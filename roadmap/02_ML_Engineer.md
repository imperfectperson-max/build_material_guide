# ðŸ¤– Machine Learning Engineer â€” Detailed Roadmap

**Team Member:** Member 2  
**Primary Tech Stack:** Python, Scikit-learn, XGBoost, Prophet, TensorFlow/Keras, Pandas  
**Timeline:** March 9 â€“ June 9, 2026 (13 Weeks)

---

## ðŸš€ Getting Started â€” March 8, 2026

Complete this setup **before** Week 1 begins on March 9.

### System Requirements
- **OS:** Windows 10/11, macOS 10.15+, or Ubuntu 20.04+
- **RAM:** Minimum 8 GB (16 GB recommended)
- **Storage:** At least 20 GB free
- **GPU:** Optional locally â€” use Kaggle's free GPU for LSTM training

### Step 1 â€“ Install Python and Conda

```bash
# Download from: https://www.anaconda.com/download  OR  https://docs.conda.io/en/latest/miniconda.html
python --version   # Must be 3.9+
conda --version    # Must be 4.x+
```

### Step 2 â€“ Create Virtual Environment

```bash
conda create -n buildmat python=3.10 -y
conda activate buildmat
which python   # Should point to your conda environment
```

### Step 3 â€“ Install All Libraries

```bash
# Core data science
pip install pandas numpy scipy matplotlib seaborn plotly

# ML and time series
pip install scikit-learn statsmodels pmdarima prophet

# Gradient boosting
pip install xgboost lightgbm

# Deep learning
pip install tensorflow

# Utilities
pip install jupyter jupyterlab ipykernel openpyxl tqdm optuna mlflow shap kaggle

# Add Jupyter kernel
python -m ipykernel install --user --name=buildmat --display-name="BuildMat ML"

# Verify TensorFlow
python -c "import tensorflow as tf; print('TF:', tf.__version__); print('GPU:', tf.config.list_physical_devices('GPU'))"
```

> **Prophet install note â€” if pip fails:**
> ```bash
> conda install -c conda-forge prophet   # macOS / Linux / Windows
> ```

### Step 4 â€“ Set Up Kaggle API

```bash
# 1. Create account at https://www.kaggle.com/
# 2. Settings â†’ API â†’ Create New Token  (downloads kaggle.json)

# macOS/Linux
mkdir -p ~/.kaggle
mv ~/Downloads/kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json

# Windows (PowerShell)
mkdir $env:USERPROFILE\.kaggle
Move-Item $env:USERPROFILE\Downloads\kaggle.json $env:USERPROFILE\.kaggle\

kaggle --version        # Verify it works
kaggle datasets list    # Should list public datasets
```

**Kaggle GPU usage throughout the project:**
- Free GPU for LSTM training (30 hours/week limit â€” monitor under Settings)
- Host your processed datasets with version control
- Save trained models to the Output tab and download them

### Step 5 â€“ Project Structure

```bash
mkdir -p ~/projects/buildmat-ml
cd ~/projects/buildmat-ml
mkdir -p data/{raw,processed,external,features}
mkdir -p notebooks/{exploratory,modeling,evaluation}
mkdir -p src/{data,features,models,evaluation,visualization,api}
mkdir -p models/{baseline,advanced,production}
mkdir -p reports/{figures,metrics}
mkdir -p configs scripts tests
touch data/raw/.gitkeep data/processed/.gitkeep models/.gitkeep
```

### Step 6 â€“ Save requirements.txt

```bash
pip freeze > requirements.txt
```

### Step 7 â€“ Git Setup

```bash
git init
cat > .gitignore << 'EOF'
__pycache__/
.env
*.pyc
*.h5
*.keras
*.pkl
*.joblib
data/raw/*
!data/raw/.gitkeep
data/processed/*
!data/processed/.gitkeep
mlruns/
kaggle.json
.DS_Store
.ipynb_checkpoints/
EOF
```

### Step 8 â€“ Place the Project Dataset

```bash
# Copy SA_Building_Materials_Dataset.xlsx (generated by team) into:
cp ~/Downloads/SA_Building_Materials_Dataset.xlsx data/raw/

# Quick sanity check
python -c "
import pandas as pd
df = pd.read_excel('data/raw/SA_Building_Materials_Dataset.xlsx',
                   sheet_name='SA Supplier Price Data')
print(f'Rows: {len(df):,}  |  Columns: {df.columns.tolist()}')
"
# Expected: Rows: 13,806  |  Columns: ['record_id', 'date', ...]
```

### Setup Checklist âœ…
- [ ] Python 3.10 + Conda installed
- [ ] `buildmat` environment created and activated
- [ ] All packages installed; TensorFlow import works
- [ ] Kaggle account created, `kaggle.json` placed, `kaggle --version` works
- [ ] Project directory structure created
- [ ] Git initialised with `.gitignore`
- [ ] `SA_Building_Materials_Dataset.xlsx` in `data/raw/`

---

## ðŸ“‚ Loading the Project Dataset

The team dataset **`SA_Building_Materials_Dataset.xlsx`** has 7 sheets. All ML work loads from here â€” never from loose CSVs.

```python
# src/data/load_dataset.py
import pandas as pd

DATASET_PATH = "data/raw/SA_Building_Materials_Dataset.xlsx"

def load_supplier_prices() -> pd.DataFrame:
    """Load the main 13,806-row ML training sheet."""
    df = pd.read_excel(DATASET_PATH, sheet_name="SA Supplier Price Data")
    df["date"] = pd.to_datetime(df["date"])
    return df.sort_values("date").reset_index(drop=True)

def load_cmpi_index() -> pd.DataFrame:
    """Load Stats SA CMPI monthly index (base Dec 2016 = 100)."""
    df = pd.read_excel(DATASET_PATH, sheet_name="Stats SA CMPI Index", skiprows=2)
    df.columns = df.columns.str.strip().str.replace("\n", " ")
    df["date"] = pd.to_datetime(df["Date"])
    return df

def load_world_bank_zar() -> pd.DataFrame:
    """Load World Bank commodity prices already converted to ZAR."""
    df = pd.read_excel(DATASET_PATH, sheet_name="Derived Rand Prices", skiprows=2)
    df["date"] = pd.to_datetime(df["Date"])
    return df

def load_zar_rate() -> pd.DataFrame:
    """Load USD/ZAR monthly exchange rates."""
    df = pd.read_excel(DATASET_PATH, sheet_name="ZAR Exchange Rate", skiprows=2)
    df["date"] = pd.to_datetime(df["Date"])
    return df

if __name__ == "__main__":
    df = load_supplier_prices()
    print(f"Rows: {len(df):,}")
    print(f"Date range: {df['date'].min().date()} â†’ {df['date'].max().date()}")
    print(f"Materials: {df['material_name'].nunique()} | Suppliers: {df['supplier_name'].nunique()}")
```

---

## ðŸ“‹ Schema Validation

The canonical dataset has exactly **16 columns**. Always validate on load â€” this catches issues early before training.

```python
# src/data/schema_loader.py
import pandas as pd
from typing import List   # â† required: List used below

REQUIRED_COLUMNS: List[str] = [
    "record_id", "date", "year", "month", "material_name", "material_category",
    "supplier_name", "region", "province", "price_zar", "unit", "price_per_kg_zar",
    "price_change_mom_pct", "price_change_yoy_pct", "stock_status", "bulk_discount_available"
]
NUMERIC_COLUMNS  = ["year", "month", "price_zar", "price_per_kg_zar",
                    "price_change_mom_pct", "price_change_yoy_pct"]
VALID_STOCK      = {"In Stock", "Low Stock", "Out of Stock"}
VALID_BULK       = {"Yes", "No"}


def load_and_validate(filepath: str,
                      sheet: str = "SA Supplier Price Data") -> pd.DataFrame:
    """Load from Excel and validate the 16-column schema."""
    df = pd.read_excel(filepath, sheet_name=sheet)
    df["date"] = pd.to_datetime(df["date"])

    missing = set(REQUIRED_COLUMNS) - set(df.columns)
    if missing:
        raise ValueError(f"Missing columns: {missing}")
    df = df[REQUIRED_COLUMNS]

    for col in NUMERIC_COLUMNS:
        df[col] = pd.to_numeric(df[col], errors="coerce")

    bad_stock = set(df["stock_status"].unique()) - VALID_STOCK
    if bad_stock:
        raise ValueError(f"Invalid stock_status values: {bad_stock}")
    bad_bulk = set(df["bulk_discount_available"].unique()) - VALID_BULK
    if bad_bulk:
        raise ValueError(f"Invalid bulk_discount_available values: {bad_bulk}")

    nulls = df.isnull().sum()
    if nulls.any():
        print(f"âš   Nulls:\n{nulls[nulls > 0]}")

    print(f"âœ… Validated â€” {len(df):,} rows | "
          f"{df['material_name'].nunique()} materials | "
          f"{df['supplier_name'].nunique()} suppliers")
    return df


def load_by_material(filepath: str, material_name: str) -> pd.DataFrame:
    df = load_and_validate(filepath)
    result = df[df["material_name"] == material_name].copy().sort_values("date")
    if result.empty:
        raise ValueError(f"No data for: {material_name}")
    return result
```

---

## ðŸ“… WEEK 1 â€” March 9â€“15, 2026
### Data Collection & Exploratory Analysis

#### Monday (March 9)

**Morning â€” environment setup + load dataset:**

```bash
conda activate buildmat
cd ~/projects/buildmat-ml
jupyter lab
```

```python
# notebooks/00_environment_test.ipynb
import pandas as pd, numpy as np, matplotlib.pyplot as plt
import seaborn as sns, tensorflow as tf, xgboost as xgb
from prophet import Prophet
from sklearn import __version__ as sk_ver

print(f"Pandas {pd.__version__} | NumPy {np.__version__} | "
      f"sklearn {sk_ver} | XGBoost {xgb.__version__} | TF {tf.__version__}")
print("GPU:", tf.config.list_physical_devices("GPU"))
```

**Afternoon â€” verify dataset:**

```python
from src.data.schema_loader import load_and_validate

DATASET = "data/raw/SA_Building_Materials_Dataset.xlsx"
df = load_and_validate(DATASET)
print(df.describe())
print(df["material_name"].value_counts())
```

**Deliverable:** All imports work; dataset loads and passes validation.

#### Tuesday (March 10)

**Full day â€” data exploration:**

```python
# notebooks/01_eda.ipynb
import pandas as pd, matplotlib.pyplot as plt, seaborn as sns
from statsmodels.tsa.stattools import adfuller
from src.data.schema_loader import load_and_validate

DATASET = "data/raw/SA_Building_Materials_Dataset.xlsx"
df = load_and_validate(DATASET)

# Aggregate to monthly average per material (multiple suppliers â†’ one line)
monthly = (df.groupby(["date", "material_name"])["price_zar"]
             .mean().reset_index())

# Time series plot per material
for mat in monthly["material_name"].unique():
    sub = monthly[monthly["material_name"] == mat]
    plt.figure(figsize=(12, 4))
    plt.plot(sub["date"], sub["price_zar"])
    plt.title(f"{mat} â€” Monthly Average Price (ZAR)")
    plt.xlabel("Date"); plt.ylabel("Price (R)")
    plt.tight_layout()
    plt.savefig(f"reports/figures/trend_{mat.replace(' ', '_')}.png")
    plt.close()
```

**Deliverable:** Price trend plots saved for all 18 materials.

#### Wednesday (March 11)

**Full day â€” stationarity + decomposition:**

```python
from statsmodels.tsa.seasonal import seasonal_decompose

# Stationarity test (Augmented Dickey-Fuller)
cement = (df[df["material_name"] == "PPC Cement 50kg"]
            .groupby("date")["price_zar"].mean())

result = adfuller(cement.dropna())
print(f"ADF statistic: {result[0]:.4f}")
print(f"p-value:       {result[1]:.4f}")
print(f"Stationary:    {'YES' if result[1] < 0.05 else 'NO â€” will need differencing in ARIMA'}")

# Seasonal decomposition
cement_monthly = cement.asfreq("MS").interpolate()
decomp = seasonal_decompose(cement_monthly, model="additive", period=12)
decomp.plot()
plt.tight_layout()
plt.savefig("reports/figures/decomposition_cement.png")
```

**Deliverable:** Stationarity results documented; seasonality plots for at least 3 materials.

#### Thursday (March 12)

**Full day â€” correlations + ACF/PACF for ARIMA prep:**

```python
# Cross-material correlation heatmap
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

pivot = (df.groupby(["date", "material_category"])["price_zar"]
           .mean().unstack("material_category"))
corr = pivot.corr()

plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap="coolwarm", center=0, fmt=".2f")
plt.title("Material Category Price Correlations")
plt.tight_layout()
plt.savefig("reports/figures/correlation_matrix.png")

# ACF / PACF â€” use these to choose p, q for ARIMA next week
fig, axes = plt.subplots(1, 2, figsize=(14, 4))
plot_acf(cement_monthly.dropna(),  lags=24, ax=axes[0])
plot_pacf(cement_monthly.dropna(), lags=24, ax=axes[1])
plt.tight_layout()
plt.savefig("reports/figures/acf_pacf_cement.png")
```

**Deliverable:** Correlation heatmap + ACF/PACF plots.

#### Friday (March 13) â€” Feature Engineering Pipeline

```python
# src/features/engineer.py
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from typing import List


class FeatureEngineer:
    """Build ML-ready features from the 16-column schema."""

    def __init__(self):
        self.encoders: dict = {}

    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:
        return self._engineer(df, fit=True)

    def transform(self, df: pd.DataFrame) -> pd.DataFrame:
        return self._engineer(df, fit=False)

    def _engineer(self, df: pd.DataFrame, fit: bool) -> pd.DataFrame:
        df = df.copy()
        df["date"] = pd.to_datetime(df["date"])

        # â”€â”€ Time features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        df["day_of_week"]  = df["date"].dt.dayofweek
        df["day_of_month"] = df["date"].dt.day
        df["quarter"]      = df["date"].dt.quarter
        df["is_month_end"] = df["date"].dt.is_month_end.astype(int)
        # Cyclical: Jan(1) and Dec(12) are neighbours, not opposites
        df["month_sin"] = np.sin(2 * np.pi * df["month"] / 12)
        df["month_cos"] = np.cos(2 * np.pi * df["month"] / 12)

        # â”€â”€ Categorical encoding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        df["stock_status_enc"]  = df["stock_status"].map(
            {"In Stock": 2, "Low Stock": 1, "Out of Stock": 0})
        df["bulk_discount_enc"] = (df["bulk_discount_available"] == "Yes").astype(int)

        for col in ["region", "province", "supplier_name", "material_category"]:
            enc_col = f"{col}_enc"
            if fit:
                self.encoders[col] = LabelEncoder().fit(df[col])
            df[enc_col] = self.encoders[col].transform(df[col])

        # â”€â”€ Lag + rolling features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # IMPORTANT: sort within each group BEFORE lagging/rolling
        df = df.sort_values(["material_name", "supplier_name", "date"])
        grp = df.groupby(["material_name", "supplier_name"])["price_zar"]
        df["price_lag_1"]  = grp.shift(1)
        df["price_lag_7"]  = grp.shift(7)
        df["price_lag_30"] = grp.shift(30)

        df["price_roll_mean_7"]  = grp.transform(lambda x: x.rolling(7,  min_periods=1).mean())
        df["price_roll_mean_30"] = grp.transform(lambda x: x.rolling(30, min_periods=1).mean())
        df["price_roll_std_7"]   = grp.transform(lambda x: x.rolling(7,  min_periods=1).std().fillna(0))

        return df

    def get_feature_cols(self) -> List[str]:
        return [
            "year", "month", "day_of_week", "day_of_month", "quarter", "is_month_end",
            "month_sin", "month_cos",
            "price_per_kg_zar", "price_change_mom_pct", "price_change_yoy_pct",
            "stock_status_enc", "bulk_discount_enc",
            "region_enc", "province_enc", "supplier_name_enc", "material_category_enc",
            "price_lag_1", "price_lag_7", "price_lag_30",
            "price_roll_mean_7", "price_roll_mean_30", "price_roll_std_7",
        ]
```

**Deliverable:** Feature engineering pipeline tested on cement data.

---

## CMPI + World Bank Feature Adders

These add external index signals as additional training features. Run them after basic feature engineering.

```python
# src/features/cmpi_feature_adder.py
import pandas as pd

class CMPIFeatureAdder:
    """
    Merges Stats SA CMPI index onto price records by (year, month).
    CMPI data comes from the 'Stats SA CMPI Index' sheet of the Excel workbook.
    Real growth rates used in dataset: 2023=+6.6%, 2024=+6.5%, 2025=+0.7%
    """

    CATEGORY_TO_CMPI = {
        "Cement":   "Cement & Concrete Work",
        "Steel":    "Steel & Metal Work",
        "Copper":   "Steel & Metal Work",    # closest proxy
        "PVC":      "Pipes & Pipelines",
        "Timber":   "Building Construction",
        "Bitumen":  "Civil Engineering Construction",
        "Masonry":  "Building Construction",
        "Sand & Aggregates": "Civil Engineering Construction",
    }

    def __init__(self, excel_path: str):
        raw = pd.read_excel(excel_path, sheet_name="Stats SA CMPI Index", skiprows=2)
        raw.columns = raw.columns.str.strip().str.replace("\n", " ")
        raw["date"] = pd.to_datetime(raw["Date"])
        self.cmpi_df = raw[["date", "Year", "Month",
                             "Total CMPI  (All Construction)",
                             "Building  Construction",
                             "Civil Engineering  Construction",
                             "Cement &  Concrete Work",
                             "Steel &  Metal Work",
                             "Pipes &  Pipelines"]].copy()
        self.cmpi_df.columns = ["date", "year", "month", "Total_CMPI",
                                "Building_CMPI", "Civil_CMPI",
                                "Cement_CMPI", "Steel_CMPI", "Pipes_CMPI"]
        print(f"âœ… Loaded CMPI index: {len(self.cmpi_df)} months")

    def add_cmpi_features(self, df: pd.DataFrame) -> pd.DataFrame:
        df = df.copy()
        df = df.merge(self.cmpi_df[["year", "month", "Total_CMPI",
                                     "Cement_CMPI", "Steel_CMPI",
                                     "Pipes_CMPI", "Building_CMPI"]],
                      on=["year", "month"], how="left")

        # Category-specific CMPI column
        col_map = {"Cement": "Cement_CMPI", "Steel": "Steel_CMPI",
                   "Copper": "Steel_CMPI",  "PVC":   "Pipes_CMPI"}
        df["category_cmpi"] = df["material_category"].map(col_map).fillna("Building_CMPI")
        df["category_cmpi"] = df.apply(
            lambda r: r[r["category_cmpi"]] if r["category_cmpi"] in df.columns else r["Building_CMPI"],
            axis=1
        )

        # MoM CMPI change per material/supplier group
        df = df.sort_values(["material_name", "supplier_name", "date"])
        df["cmpi_change_mom"] = (df.groupby(["material_name", "supplier_name"])["Total_CMPI"]
                                   .pct_change() * 100)
        print("âœ… Added CMPI features")
        return df


# Usage
DATASET = "data/raw/SA_Building_Materials_Dataset.xlsx"
cmpi_adder = CMPIFeatureAdder(DATASET)
df_with_cmpi = cmpi_adder.add_cmpi_features(df_features)
```

```python
# src/features/world_bank_feature_adder.py
import pandas as pd

class WorldBankFeatureAdder:
    """
    Merges World Bank commodity prices (already in ZAR) onto price records.
    Source: 'Derived Rand Prices' sheet in SA_Building_Materials_Dataset.xlsx.
    Commodities: Copper, Steel Rebar, Timber
    """

    def __init__(self, excel_path: str):
        raw = pd.read_excel(excel_path, sheet_name="Derived Rand Prices", skiprows=2)
        raw.columns = raw.columns.str.strip().str.replace("\n", " ")
        raw["date"] = pd.to_datetime(raw["Date"])
        self.wb_df = raw[["date", "Year", "Month",
                           "Copper ZAR/mt", "Steel ZAR/mt", "Timber ZAR/mÂ³"]].copy()
        self.wb_df.columns = ["date", "year", "month",
                               "Copper_ZAR", "Steel_ZAR", "Timber_ZAR"]
        print(f"âœ… Loaded World Bank ZAR prices: {len(self.wb_df)} months")

    def add_world_bank_features(self, df: pd.DataFrame) -> pd.DataFrame:
        df = df.copy()
        df = df.merge(self.wb_df[["year", "month",
                                   "Copper_ZAR", "Steel_ZAR", "Timber_ZAR"]],
                      on=["year", "month"], how="left")
        print("âœ… Added World Bank ZAR commodity features")
        return df


# Usage
wb_adder = WorldBankFeatureAdder(DATASET)
df_enriched = wb_adder.add_world_bank_features(df_with_cmpi)
```

---

## ðŸ“… WEEK 2 â€” March 16â€“22, 2026
### Baseline Models â€” NaÃ¯ve, Moving Average, ARIMA

#### Monday (March 16) â€” Evaluation Framework

```python
# src/evaluation/metrics.py
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error
from typing import Dict


def evaluate(y_true: np.ndarray, y_pred: np.ndarray,
             model_name: str = "") -> Dict[str, float]:
    mae  = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mask = y_true != 0
    mape = float(np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100)
    metrics = {"MAE": round(mae, 4), "RMSE": round(rmse, 4), "MAPE": round(mape, 2)}
    if model_name:
        print(f"{model_name:25s}  MAE={mae:.2f}  RMSE={rmse:.2f}  MAPE={mape:.2f}%")
    return metrics


def time_series_split(df: "pd.DataFrame", test_months: int = 3):
    """
    Temporal split â€” NEVER split randomly on time-series data.
    Uses the last `test_months` months as the test set.
    """
    import pandas as pd
    df = df.sort_values("date")
    cutoff = df["date"].max() - pd.DateOffset(months=test_months)
    train = df[df["date"] <= cutoff].copy()
    test  = df[df["date"] >  cutoff].copy()
    print(f"Train: {train['date'].min().date()} â†’ {train['date'].max().date()} ({len(train):,})")
    print(f"Test:  {test['date'].min().date()}  â†’ {test['date'].max().date()}  ({len(test):,})")
    return train, test
```

#### Tuesday (March 17) â€” NaÃ¯ve + Moving Average

```python
# src/models/naive.py
import numpy as np

class NaiveForecast:
    """Persistence model â€” next price = last known price."""
    def fit(self, y_train):
        self._last = float(y_train.iloc[-1])
        return self
    def predict(self, steps: int) -> np.ndarray:
        return np.full(steps, self._last)


# src/models/moving_average.py
class MovingAverageModel:
    def __init__(self, window: int = 7):
        self.window = window

    def fit(self, y_train):
        self._history = list(y_train.values)
        return self

    def predict(self, steps: int) -> np.ndarray:
        history = self._history.copy()
        preds = []
        for _ in range(steps):
            p = float(np.mean(history[-self.window:]))
            preds.append(p)
            history.append(p)   # use prediction for next step
        return np.array(preds)
```

#### Wednesday (March 18) â€” ARIMA

```python
# src/models/arima_model.py
from statsmodels.tsa.arima.model import ARIMA
from itertools import product
import warnings, numpy as np
warnings.filterwarnings("ignore")   # convergence warnings are normal here


class ARIMAForecaster:
    def __init__(self, order=(1, 1, 1)):
        self.order = order
        self._fitted = None

    def fit(self, y_train):
        self._fitted = ARIMA(y_train, order=self.order).fit()
        return self

    def predict(self, steps: int) -> np.ndarray:
        return self._fitted.forecast(steps=steps).values

    @property
    def aic(self):
        return self._fitted.aic


def auto_arima(y_train, max_p=2, max_d=1, max_q=2) -> ARIMAForecaster:
    """Grid-search for best (p,d,q) by AIC."""
    best_aic, best_order = np.inf, None
    for p, d, q in product(range(max_p + 1), range(max_d + 1), range(max_q + 1)):
        try:
            m = ARIMA(y_train, order=(p, d, q)).fit()
            if m.aic < best_aic:
                best_aic, best_order = m.aic, (p, d, q)
        except Exception:
            continue
    print(f"Best ARIMA order: {best_order}  AIC: {best_aic:.2f}")
    return ARIMAForecaster(best_order).fit(y_train)
```

#### Thursdayâ€“Friday â€” Run All Baselines + Save Benchmark

```python
# notebooks/02_baseline_models.ipynb
import pandas as pd, json
from src.data.schema_loader import load_and_validate
from src.evaluation.metrics import evaluate, time_series_split
from src.models.naive import NaiveForecast
from src.models.moving_average import MovingAverageModel
from src.models.arima_model import auto_arima

DATASET = "data/raw/SA_Building_Materials_Dataset.xlsx"
df = load_and_validate(DATASET)

# Monthly average per date (collapse suppliers)
cement = (df[df["material_name"] == "PPC Cement 50kg"]
            .groupby("date")["price_zar"].mean()
            .reset_index().rename(columns={"price_zar": "price"}))

train, test = time_series_split(cement, test_months=3)
results = {}

# NaÃ¯ve
naive = NaiveForecast().fit(train["price"])
results["Naive"] = evaluate(test["price"].values, naive.predict(len(test)), "NaÃ¯ve")

# Moving Average (try 3 windows)
for w in [3, 7, 14]:
    ma = MovingAverageModel(w).fit(train["price"])
    results[f"MA_w{w}"] = evaluate(test["price"].values, ma.predict(len(test)), f"MA(w={w})")

# ARIMA (auto-tune by AIC)
arima = auto_arima(train["price"])
results["ARIMA"] = evaluate(test["price"].values, arima.predict(len(test)), "ARIMA")

# Save benchmark â€” this is the bar every advanced model must beat
with open("models/baseline/baseline_results.json", "w") as f:
    json.dump(results, f, indent=2)
print("âœ… Baseline benchmark saved.")
```

**Deliverable:** `baseline_results.json` with NaÃ¯ve, MA (3 windows), ARIMA metrics.

---

## ðŸ“… WEEK 3 â€” March 23â€“29, 2026
### Advanced Models â€” XGBoost & Random Forest

#### Monday (March 23) â€” D1 Prep + Start XGBoost

Prepare D1 slides showing baseline results (MAPE table, trend plots, methodology). Also start XGBoost implementation.

#### D1 Demo â€” Wednesday (March 25) ðŸŽ¯

Show baseline results, preliminary XGBoost numbers, and feature importance charts.

#### Tuesdayâ€“Thursday â€” XGBoost

```python
# src/models/xgboost_model.py
import numpy as np, pandas as pd, xgboost as xgb, joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from typing import List


class XGBoostForecaster:
    def __init__(self, **params):
        defaults = dict(n_estimators=200, max_depth=5, learning_rate=0.05,
                        subsample=0.8, colsample_bytree=0.8,
                        objective="reg:squarederror", random_state=42)
        defaults.update(params)
        self.model  = xgb.XGBRegressor(**defaults)
        self.scaler = StandardScaler()
        self.feature_cols: List[str] = []

    def fit(self, X: pd.DataFrame, y: pd.Series):
        self.feature_cols = list(X.columns)   # store BEFORE training
        Xs = self.scaler.fit_transform(X)
        # NOTE: early_stopping_rounds moved to fit() in XGBoost â‰¥ 2.0
        self.model.fit(Xs, y,
                       eval_set=[(Xs, y)],
                       verbose=False)
        return self

    def predict(self, X: pd.DataFrame) -> np.ndarray:
        return self.model.predict(self.scaler.transform(X[self.feature_cols]))

    def feature_importance(self) -> pd.DataFrame:
        return (pd.DataFrame({"feature": self.feature_cols,
                               "importance": self.model.feature_importances_})
                  .sort_values("importance", ascending=False))

    def save(self, path: str):
        joblib.dump(self, path)

    @staticmethod
    def load(path: str) -> "XGBoostForecaster":
        return joblib.load(path)


def tune_xgboost(X_train: pd.DataFrame, y_train: pd.Series) -> dict:
    param_grid = {
        "n_estimators":     [100, 200, 300],
        "max_depth":        [3, 5, 7],
        "learning_rate":    [0.01, 0.05, 0.1],
        "subsample":        [0.8, 1.0],
        "colsample_bytree": [0.8, 1.0],
    }
    tscv = TimeSeriesSplit(n_splits=5)
    gs = GridSearchCV(
        xgb.XGBRegressor(objective="reg:squarederror", random_state=42),
        param_grid, cv=tscv, scoring="neg_mean_absolute_error", n_jobs=-1
    )
    gs.fit(X_train, y_train)
    print(f"Best params: {gs.best_params_}")
    print(f"Best CV MAE: {-gs.best_score_:.2f}")
    return gs.best_params_
```

#### Thursday (March 26) â€” Random Forest

```python
# src/models/random_forest.py
import numpy as np, pandas as pd, joblib
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from typing import List


class RandomForestForecaster:
    def __init__(self, n_estimators=200, max_depth=10, **kwargs):
        self.model  = RandomForestRegressor(n_estimators=n_estimators,
                                             max_depth=max_depth,
                                             random_state=42, n_jobs=-1, **kwargs)
        self.scaler = StandardScaler()
        self.feature_cols: List[str] = []

    def fit(self, X: pd.DataFrame, y: pd.Series):
        self.feature_cols = list(X.columns)   # store BEFORE training
        self.model.fit(self.scaler.fit_transform(X), y)
        return self

    def predict(self, X: pd.DataFrame) -> np.ndarray:
        return self.model.predict(self.scaler.transform(X[self.feature_cols]))

    def feature_importance(self) -> pd.DataFrame:
        # Use self.feature_cols â€” NOT X_train.columns (which may be out of scope)
        return (pd.DataFrame({"feature": self.feature_cols,
                               "importance": self.model.feature_importances_})
                  .sort_values("importance", ascending=False))

    def save(self, path: str):
        joblib.dump(self, path)
```

#### Friday (March 27) â€” Train + Compare

```python
# notebooks/03_tree_models.ipynb
import joblib, json, pandas as pd
from src.data.schema_loader import load_and_validate
from src.features.engineer import FeatureEngineer
from src.evaluation.metrics import evaluate, time_series_split
from src.models.xgboost_model import XGBoostForecaster, tune_xgboost
from src.models.random_forest import RandomForestForecaster

DATASET = "data/raw/SA_Building_Materials_Dataset.xlsx"
df = load_and_validate(DATASET)

eng = FeatureEngineer()
df_feat = eng.fit_transform(df)
feat_cols = eng.get_feature_cols()
df_feat = df_feat.dropna(subset=feat_cols)   # drop NaN rows from lagging

train, test = time_series_split(df_feat, test_months=3)
X_train, y_train = train[feat_cols], train["price_zar"]
X_test,  y_test  = test[feat_cols],  test["price_zar"]

# XGBoost â€” tune then train
best_params  = tune_xgboost(X_train, y_train)
xgb_model    = XGBoostForecaster(**best_params).fit(X_train, y_train)
xgb_metrics  = evaluate(y_test.values, xgb_model.predict(X_test), "XGBoost (tuned)")

# Random Forest
rf_model     = RandomForestForecaster().fit(X_train, y_train)
rf_metrics   = evaluate(y_test.values, rf_model.predict(X_test), "Random Forest")

# Compare improvement over ARIMA baseline
with open("models/baseline/baseline_results.json") as f:
    baseline = json.load(f)
arima_mape = baseline["ARIMA"]["MAPE"]

for name, m in [("XGBoost", xgb_metrics), ("Random Forest", rf_metrics)]:
    pct = (arima_mape - m["MAPE"]) / arima_mape * 100
    print(f"{name}: {pct:.1f}% improvement over ARIMA")

# Persist
joblib.dump(xgb_model, "models/advanced/xgboost.pkl")
joblib.dump(rf_model,  "models/advanced/random_forest.pkl")
joblib.dump(eng,       "models/advanced/feature_engineer.pkl")
```

**Deliverable:** Both models trained, saved, and compared vs ARIMA baseline.

---

## ðŸ“… WEEK 4 â€” March 30â€“April 5, 2026
### Prophet + LSTM (Local CPU + Kaggle GPU)

#### ST1 Demo â€” Wednesday (April 1) ðŸŽ¯

Show architecture diagram, all model metrics so far, feature importance charts, and live Prophet forecast.

#### Monday (March 30) â€” Prophet

```python
# src/models/prophet_model.py
import pandas as pd, numpy as np
from prophet import Prophet


class ProphetForecaster:
    def __init__(self, changepoint_prior_scale=0.05):
        self.model = Prophet(
            yearly_seasonality=True,
            weekly_seasonality=False,   # monthly data â€” no weekly pattern
            daily_seasonality=False,
            changepoint_prior_scale=changepoint_prior_scale,
        )

    def fit(self, df: pd.DataFrame):
        """df must have columns: date, price_zar"""
        prophet_df = df.rename(columns={"date": "ds", "price_zar": "y"})[["ds", "y"]]
        self.model.fit(prophet_df)
        return self

    def predict(self, steps: int) -> np.ndarray:
        # freq="MS" = Month Start â€” required for monthly price data
        future = self.model.make_future_dataframe(periods=steps, freq="MS")
        return self.model.predict(future).tail(steps)["yhat"].values

    def plot_components(self, steps: int = 12):
        future = self.model.make_future_dataframe(periods=steps, freq="MS")
        forecast = self.model.predict(future)
        self.model.plot_components(forecast)
```

#### Tuesdayâ€“Friday â€” LSTM Training on Kaggle GPU

> âš ï¸ **Do NOT train LSTM locally.** Use Kaggle's free GPU (30 hrs/week). Steps below.

**Step 1 â€” Export the supplier prices sheet to CSV for Kaggle upload:**

```python
# Run locally before uploading
import pandas as pd
df = pd.read_excel("data/raw/SA_Building_Materials_Dataset.xlsx",
                   sheet_name="SA Supplier Price Data")
df.to_csv("data/processed/supplier_prices.csv", index=False)
print(f"Exported {len(df):,} rows")
```

**Step 2 â€” Upload to Kaggle:**

```bash
cd data/processed/

# Create metadata file
cat > dataset-metadata.json << 'EOF'
{
  "title": "SA Building Materials Prices",
  "id": "your-username/sa-building-materials-prices",
  "licenses": [{"name": "CC0-1.0"}]
}
EOF

kaggle datasets create -p .
# To update later: kaggle datasets version -p . -m "Version 2 â€” added scraper data"
```

**Step 3 â€” Create Kaggle Notebook:**
1. Go to `kaggle.com/code` â†’ New Notebook
2. Settings â†’ Accelerator â†’ **GPU T4 x2** (free!)
3. Settings â†’ Internet â†’ **On**
4. Add Data â†’ your uploaded dataset

**Step 4 â€” Full LSTM Notebook (paste into Kaggle cells):**

```python
# â”€â”€ Cell 1: Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os, json
import numpy as np, pandas as pd, matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

np.random.seed(42); tf.random.set_seed(42)

# Prevent OOM errors
for gpu in tf.config.list_physical_devices("GPU"):
    tf.config.experimental.set_memory_growth(gpu, True)

print("TF:", tf.__version__)
print("GPUs:", tf.config.list_physical_devices("GPU"))
```

```python
# â”€â”€ Cell 2: Load Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# List all input files
for d, _, files in os.walk("/kaggle/input"):
    for f in files:
        print(os.path.join(d, f))

df = pd.read_csv("/kaggle/input/sa-building-materials-prices/supplier_prices.csv",
                 parse_dates=["date"])

MATERIAL = "PPC Cement 50kg"
mat_df = (df[df["material_name"] == MATERIAL]
            .groupby("date")["price_zar"].mean()
            .reset_index().sort_values("date"))

print(f"Records for {MATERIAL}: {len(mat_df)}")
print(mat_df.head())
```

```python
# â”€â”€ Cell 3: Preprocessing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SEQ_LEN = 12   # 12 months lookback (data is monthly)

scaler = MinMaxScaler(feature_range=(0, 1))
prices_scaled = scaler.fit_transform(mat_df[["price_zar"]].values)

def create_sequences(data, seq_len):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i : i + seq_len])
        y.append(data[i + seq_len])
    return np.array(X), np.array(y)

X, y = create_sequences(prices_scaled, SEQ_LEN)

# Temporal split â€” NO shuffle
split = int(0.8 * len(X))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

print(f"X_train: {X_train.shape}  X_test: {X_test.shape}")
```

```python
# â”€â”€ Cell 4: Build Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_lstm(seq_len, n_features=1):
    model = Sequential([
        Bidirectional(LSTM(64, return_sequences=True),
                      input_shape=(seq_len, n_features)),
        Dropout(0.2),
        LSTM(64, return_sequences=True),
        Dropout(0.2),
        LSTM(32, return_sequences=False),
        Dropout(0.2),
        Dense(32, activation="relu"),
        Dense(1),
    ])
    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),
                  loss="mse", metrics=["mae"])
    model.summary()
    return model

lstm = build_lstm(SEQ_LEN)
```

```python
# â”€â”€ Cell 5: Train â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
callbacks = [
    EarlyStopping(monitor="val_loss", patience=15,
                  restore_best_weights=True, verbose=1),
    ModelCheckpoint("/kaggle/working/lstm_best.keras",
                    monitor="val_loss", save_best_only=True, verbose=1),
    ReduceLROnPlateau(monitor="val_loss", factor=0.5,
                      patience=5, min_lr=1e-6, verbose=1),
]

history = lstm.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=150,
    batch_size=16,    # keep small â€” monthly data has few samples
    callbacks=callbacks,
    verbose=1,
)

# Epochs actually trained (EarlyStopping may have stopped early)
epochs_trained = len(history.history["loss"])
print(f"Epochs trained: {epochs_trained}")
```

```python
# â”€â”€ Cell 6: Evaluate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
y_pred_scaled = lstm.predict(X_test, verbose=0)
y_pred = scaler.inverse_transform(y_pred_scaled)
y_true = scaler.inverse_transform(y_test)

mae  = mean_absolute_error(y_true, y_pred)
rmse = np.sqrt(mean_squared_error(y_true, y_pred))
mape = float(np.mean(np.abs((y_true - y_pred) / y_true)) * 100)
print(f"LSTM  MAE={mae:.2f}  RMSE={rmse:.2f}  MAPE={mape:.2f}%")

plt.figure(figsize=(12, 4))
plt.plot(y_true, label="Actual")
plt.plot(y_pred, label="LSTM Predicted", linestyle="--")
plt.title(f"LSTM Forecast â€” {MATERIAL}")
plt.legend(); plt.tight_layout()
plt.savefig("/kaggle/working/lstm_forecast.png", dpi=200)
plt.show()
```

```python
# â”€â”€ Cell 7: Save Artifacts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
metrics = {
    "MAE": float(mae), "RMSE": float(rmse), "MAPE": float(mape),
    "material": MATERIAL, "seq_len": SEQ_LEN,
    "epochs_trained": epochs_trained,    # use history length, NOT early_stop.best_epoch
    "train_samples": int(len(X_train)), "test_samples": int(len(X_test)),
}
with open("/kaggle/working/lstm_metrics.json", "w") as f:
    json.dump(metrics, f, indent=2)

np.save("/kaggle/working/scaler_min.npy", scaler.data_min_)
np.save("/kaggle/working/scaler_max.npy", scaler.data_max_)

print("âœ… Saved: lstm_best.keras, lstm_metrics.json, lstm_forecast.png")
print("   â†’ Download from the Output tab on the right â†’")
```

**After training â€” move downloads locally:**

```bash
mv ~/Downloads/lstm_best.keras       models/advanced/
mv ~/Downloads/lstm_metrics.json     reports/
mv ~/Downloads/lstm_forecast.png     reports/figures/
```

---

#### Thursday (April 3) â€” Local LSTM (CPU/GPU) for Comparison & Iteration

> **Why both?** Use Kaggle for serious training (full epochs, GPU speed). Use local for rapid architecture experiments and debugging â€” shorter epochs, instant feedback.

```python
# src/models/lstm_model.py
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
from typing import Tuple
import json


class LSTMForecaster:
    """
    Lightweight LSTM for local training and quick iteration.
    Use the Kaggle version (Bidirectional, deeper) for production.
    """

    def __init__(self, seq_len: int = 12, units: int = 50):
        self.seq_len = seq_len
        self.units   = units
        self.scaler  = MinMaxScaler(feature_range=(0, 1))
        self.model   = None

    def _build(self) -> tf.keras.Model:
        model = Sequential([
            LSTM(self.units, return_sequences=True,
                 input_shape=(self.seq_len, 1)),
            Dropout(0.2),
            LSTM(self.units, return_sequences=False),
            Dropout(0.2),
            Dense(25, activation="relu"),
            Dense(1),
        ])
        model.compile(optimizer="adam", loss="mse", metrics=["mae"])
        return model

    @staticmethod
    def create_sequences(data: np.ndarray,
                         seq_len: int) -> Tuple[np.ndarray, np.ndarray]:
        X, y = [], []
        for i in range(len(data) - seq_len):
            X.append(data[i : i + seq_len])
            y.append(data[i + seq_len])
        return np.array(X), np.array(y)

    def fit(self, prices: pd.Series,
            save_path: str = "models/advanced/lstm_local_best.keras",
            epochs: int = 100, batch_size: int = 16) -> dict:
        """
        prices: a pandas Series of price values, sorted by date.
        Returns training history metrics.
        """
        values = prices.values.reshape(-1, 1)
        scaled = self.scaler.fit_transform(values)

        X, y = self.create_sequences(scaled, self.seq_len)

        # Temporal split â€” 80/20, NO shuffle
        split      = int(0.8 * len(X))
        X_train, X_test = X[:split], X[split:]
        y_train, y_test = y[:split], y[split:]

        print(f"LSTM Train: {X_train.shape}  Test: {X_test.shape}")

        self.model = self._build()
        self.model.summary()

        callbacks = [
            EarlyStopping(monitor="val_loss", patience=10,
                          restore_best_weights=True, verbose=1),
            ModelCheckpoint(save_path, monitor="val_loss",
                            save_best_only=True, verbose=1),
        ]

        history = self.model.fit(
            X_train, y_train,
            validation_split=0.2,
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=1,
        )

        # Evaluate on held-out test
        y_pred_s = self.model.predict(X_test, verbose=0)
        y_pred   = self.scaler.inverse_transform(y_pred_s)
        y_true   = self.scaler.inverse_transform(y_test)

        mae  = float(mean_absolute_error(y_true, y_pred))
        rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))
        mape = float(np.mean(np.abs((y_true - y_pred) / y_true)) * 100)

        # epochs_trained from history length â€” NOT early_stop.best_epoch (doesn't exist)
        epochs_trained = len(history.history["loss"])

        metrics = {"MAE": round(mae, 4), "RMSE": round(rmse, 4),
                   "MAPE": round(mape, 2), "epochs_trained": epochs_trained}
        print(f"\nLocal LSTM  MAE={mae:.2f}  RMSE={rmse:.2f}  MAPE={mape:.2f}%")
        return metrics

    def predict_steps(self, last_sequence: np.ndarray,
                      steps: int) -> np.ndarray:
        """
        Multi-step forecast: feed predictions back as input.
        last_sequence: last `seq_len` raw (unscaled) price values.
        """
        seq = self.scaler.transform(
            last_sequence.reshape(-1, 1)).flatten()
        preds = []

        for _ in range(steps):
            x = seq[-self.seq_len:].reshape(1, self.seq_len, 1)
            p = self.model.predict(x, verbose=0)[0, 0]
            preds.append(p)
            seq = np.append(seq, p)

        return self.scaler.inverse_transform(
            np.array(preds).reshape(-1, 1)).flatten()
```

```python
# notebooks/04b_lstm_local.ipynb
import pandas as pd, matplotlib.pyplot as plt, json
from src.data.schema_loader import load_and_validate
from src.evaluation.metrics import evaluate, time_series_split
from src.models.lstm_model import LSTMForecaster

DATASET = "data/raw/SA_Building_Materials_Dataset.xlsx"
df = load_and_validate(DATASET)

# Monthly average across all suppliers for one material
cement = (df[df["material_name"] == "PPC Cement 50kg"]
            .groupby("date")["price_zar"].mean()
            .reset_index().sort_values("date"))

lstm_local = LSTMForecaster(seq_len=12, units=50)
local_metrics = lstm_local.fit(
    cement["price_zar"],
    save_path="models/advanced/lstm_local_best.keras",
    epochs=100,
    batch_size=16,
)

# 30-day multi-step forecast
last_30 = cement["price_zar"].values[-12:]
forecast = lstm_local.predict_steps(last_30, steps=6)
print("\n6-month price forecast:")
for i, p in enumerate(forecast, 1):
    print(f"  Month +{i}: R{p:.2f}")

# Save local metrics
with open("reports/lstm_local_metrics.json", "w") as f:
    json.dump(local_metrics, f, indent=2)

# Plot
plt.figure(figsize=(12, 4))
plt.plot(cement["date"].values, cement["price_zar"].values, label="Historical")
plt.title("LSTM Local â€” Cement Price with 6-Month Forecast")
plt.legend(); plt.tight_layout()
plt.savefig("reports/figures/lstm_local_forecast.png")
print("âœ… Local LSTM training complete.")
```

#### Friday (April 4) â€” Compare Local vs Kaggle LSTM + Plot Training History

```python
# notebooks/04c_lstm_comparison.ipynb
import json, matplotlib.pyplot as plt

# Load both metric files
with open("reports/lstm_local_metrics.json")  as f: local  = json.load(f)
with open("reports/lstm_metrics.json")         as f: kaggle = json.load(f)

print("=" * 40)
print(f"{'Metric':<12} {'Local CPU':>12} {'Kaggle GPU':>12}")
print("=" * 40)
for k in ["MAE", "RMSE", "MAPE"]:
    print(f"{k:<12} {local[k]:>12.4f} {kaggle[k]:>12.4f}")
print(f"{'Epochs':<12} {local['epochs_trained']:>12} {kaggle['epochs_trained']:>12}")
print("=" * 40)
print("\nâ†’ Use the Kaggle model in production (deeper architecture + GPU training).")
print("â†’ Local model is for fast debugging and architecture experiments.")
```

**When to use which:**

| | Local LSTM | Kaggle LSTM |
|---|---|---|
| Architecture | 2-layer LSTM | Bidirectional + 3-layer LSTM |
| Training time | ~5â€“15 min (CPU) | ~2â€“5 min (GPU) |
| Use for | Debugging, quick iterations | Production model |
| Saved as | `lstm_local_best.keras` | `lstm_best.keras` |
| Deployed to API | âŒ | âœ… |

---

**Deliverable:** Prophet model + local LSTM (`lstm_local_best.keras`) + Kaggle LSTM (`lstm_best.keras`) all trained, metrics compared.

---

## ðŸ“… WEEK 5 â€” April 6â€“12, 2026
### Ensemble Model + D2 Demo

#### D2 Demo â€” Wednesday (April 8) ðŸŽ¯

Show all five models, claim the 59% improvement over ARIMA with evidence, and run a live prediction.

#### Mondayâ€“Tuesday â€” Ensemble

```python
# src/models/ensemble.py
import numpy as np
from typing import List


class WeightedEnsemble:
    """
    Combines XGBoost, Random Forest, and Prophet.
    Weights are optimised on the test/validation set by grid search.
    """

    def __init__(self, models: list, weights: List[float] = None):
        self.models  = models
        self.weights = weights

    def _predict_all(self, X=None, steps=None) -> np.ndarray:
        preds = []
        for m in self.models:
            p = m.predict(X) if X is not None else m.predict(steps)
            preds.append(np.asarray(p).flatten())
        return np.stack(preds, axis=0)   # shape: (n_models, n_samples)

    def optimise_weights(self, X_val, y_val: np.ndarray, steps=None):
        """Grid-search weights (0.0â€“1.0 in 0.1 steps) to minimise MAE."""
        all_preds = self._predict_all(X_val, steps)
        best_mae, best_w = np.inf, None

        for w0 in np.arange(0, 1.01, 0.1):
            for w1 in np.arange(0, 1.01 - w0, 0.1):
                w2 = round(1.0 - w0 - w1, 1)
                if w2 < 0:
                    continue
                w = np.array([w0, w1, w2])
                pred = (all_preds * w[:, None]).sum(axis=0)
                mae  = float(np.mean(np.abs(y_val - pred)))
                if mae < best_mae:
                    best_mae, best_w = mae, w

        self.weights = best_w
        print(f"Optimal weights: {best_w}  |  Val MAE: {best_mae:.2f}")

    def predict(self, X=None, steps=None) -> np.ndarray:
        if self.weights is None:
            raise ValueError("Call optimise_weights() first.")
        return (self._predict_all(X, steps) * np.array(self.weights)[:, None]).sum(axis=0)
```

```python
# Usage â€” notebooks/04_ensemble.ipynb
from src.models.ensemble import WeightedEnsemble
from src.evaluation.metrics import evaluate
import json

ensemble = WeightedEnsemble([xgb_model, rf_model, prophet_model])
ensemble.optimise_weights(X_test, y_test.values)
ens_preds   = ensemble.predict(X_test)
ens_metrics = evaluate(y_test.values, ens_preds, "Ensemble")

print("\n=== Improvement over ARIMA ===")
for name, m in [("XGBoost", xgb_metrics),
                ("Random Forest", rf_metrics),
                ("Ensemble", ens_metrics)]:
    pct = (arima_mape - m["MAPE"]) / arima_mape * 100
    print(f"  {name}: {pct:.1f}% improvement")
```

#### Thursdayâ€“Friday â€” Backend Integration

Work with Member 1 (backend) to wire up the model inference endpoint. See `InferenceService` in Weeks 6â€“8 section below.

---

## ðŸ“… WEEKS 6â€“8 â€” April 13â€“May 3, 2026
### Anomaly Detection + Backend Integration + MVP

#### Anomaly Detection

```python
# src/models/anomaly_detector.py
import numpy as np, pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler


class PriceAnomalyDetector:
    """
    Two detection methods:
    1. Z-score â€” fast and interpretable
    2. Isolation Forest â€” catches multivariate anomalies
    """

    def __init__(self, z_threshold: float = 2.5, contamination: float = 0.05):
        self.z_threshold   = z_threshold
        self._iso          = IsolationForest(contamination=contamination, random_state=42)
        self._scaler       = StandardScaler()
        self._fitted       = False

    def flag_zscore(self, series: pd.Series) -> pd.Series:
        mu, sigma = series.mean(), series.std()
        if sigma == 0:
            return pd.Series(False, index=series.index)
        return (series - mu).abs() / sigma > self.z_threshold

    def fit(self, X: pd.DataFrame):
        self._scaler.fit(X)
        self._iso.fit(self._scaler.transform(X))
        self._fitted = True
        return self

    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """Returns 1 (normal) or -1 (anomaly)."""
        if not self._fitted:
            raise RuntimeError("Call fit() before predict()")
        return self._iso.predict(self._scaler.transform(X))

    def detect(self, df: pd.DataFrame, price_col: str = "price_zar") -> pd.DataFrame:
        """Convenience: label the full DataFrame with anomaly flags."""
        df = df.copy()
        df["zscore_anomaly"] = self.flag_zscore(df[price_col])

        df["mom_pct"]   = df[price_col].pct_change() * 100
        df["mom_spike"] = df["mom_pct"].abs() > 10   # >10% MoM = spike alert

        df["anomaly_flag"] = df["zscore_anomaly"] | df["mom_spike"]
        return df


# Usage
detector = PriceAnomalyDetector(z_threshold=2.5)
cement_monthly = (df[df["material_name"] == "PPC Cement 50kg"]
                    .groupby("date")["price_zar"].mean().reset_index())
cement_flagged = detector.detect(cement_monthly)
alerts = cement_flagged[cement_flagged["anomaly_flag"]]
print(f"Anomalies detected: {len(alerts)}")
print(alerts[["date", "price_zar", "mom_pct"]].to_string())
```

#### Model Inference Service (for Member 1's backend)

```python
# src/api/inference_service.py
"""
Load once at API startup; share across requests.
Member 1 calls predict_price() from the Express/FastAPI route handler.
"""
import joblib, numpy as np, pandas as pd, tensorflow as tf
from src.features.engineer import FeatureEngineer


class InferenceService:
    def __init__(self, models_dir: str = "models/production"):
        self.xgb_model  = joblib.load(f"{models_dir}/xgboost.pkl")
        self.rf_model   = joblib.load(f"{models_dir}/random_forest.pkl")
        self.engineer   = joblib.load(f"{models_dir}/feature_engineer.pkl")
        self.lstm_model = tf.keras.models.load_model(f"{models_dir}/lstm_best.keras")
        print("âœ… All models loaded.")

    def predict_price(self, record: dict, horizon_days: int = 7) -> dict:
        """
        record: dict with the 16 canonical schema fields.
        Returns XGBoost, RF, and ensemble price predictions.
        """
        df   = pd.DataFrame([record])
        df   = self.engineer.transform(df)
        feat = self.engineer.get_feature_cols()
        X    = df[feat].dropna()

        if X.empty:
            raise ValueError("Not enough history to generate features "
                             "(need at least 30 prior rows for lag features).")

        xgb_pred = float(self.xgb_model.predict(X)[0])
        rf_pred  = float(self.rf_model.predict(X)[0])
        ensemble = round(xgb_pred * 0.5 + rf_pred * 0.5, 2)

        return {
            "material":     record["material_name"],
            "supplier":     record["supplier_name"],
            "xgb_pred":    round(xgb_pred, 2),
            "rf_pred":      round(rf_pred, 2),
            "ensemble":     ensemble,
            "horizon_days": horizon_days,
        }
```

**D3 (May 1) â€” MVP Complete** ðŸŽ‰

---

## ðŸ“… WEEKS 9â€“13 â€” May 4â€“June 9, 2026
### Testing, Optimisation & Final Presentation

**ST2 (May 6)** â€” Present test results and full metrics table  
**D4 (May 13)** â€” Final polish  
**Final (June 10)** â€” Championship presentation

**Focus areas:**
- Retrain models as new scraped data arrives from Member 4
- Rolling retraining pipeline (`scripts/retrain.py`)
- Document all model cards (inputs, outputs, metrics, known limitations)
- Final comparison chart â€” all 8 models, MAPE side-by-side
- Presentation slides with 59% improvement claim backed by `baseline_results.json`

---

## ðŸŽ¯ Performance Targets

| Model | MAPE Target | vs ARIMA | Week Due |
|---|---|---|---|
| NaÃ¯ve | ~15% | baseline | 2 |
| Moving Average | ~12% | baseline | 2 |
| ARIMA | ~10% | baseline | 2 |
| XGBoost (tuned) | < 6% | âˆ’40% | 3 |
| Random Forest | < 7% | âˆ’30% | 3 |
| Prophet | < 8% | âˆ’20% | 4 |
| LSTM (Kaggle) | < 6% | âˆ’40% | 4 |
| **Ensemble** | **< 5%** | **âˆ’50%+** | **5 ðŸ†** |

> The 59% MAPE improvement target is over ARIMA. XGBoost + LSTM ensemble should comfortably achieve this on CMPI-calibrated data.

---

## âš ï¸ Common Bugs & Fixes

| Bug | Cause | Fix |
|---|---|---|
| `NameError: name 'List' is not defined` | Missing import | Add `from typing import List` at the top of every file that uses it |
| `AttributeError: 'EarlyStopping' object has no attribute 'best_epoch'` | Wrong attribute name | Use `len(history.history['loss'])` to get epochs trained |
| `feature_importances_` uses wrong column names in RF | `X_train.columns` referenced after `fit()` call in wrong scope | Store `self.feature_cols = list(X.columns)` **inside** `fit()` before training |
| Rolling features return all NaN | `.groupby().transform()` called before sorting | Always `sort_values(["material_name", "supplier_name", "date"])` **before** groupby |
| ARIMA throws convergence warnings | Normal for short series | Add `warnings.filterwarnings("ignore")` at top of arima module |
| Prophet fails on monthly data | Frequency not specified | Use `freq="MS"` (Month Start) in `make_future_dataframe()` |
| LSTM predicts a flat horizontal line | Scaler mismatch | `inverse_transform` must use the **exact same scaler instance** used in `fit_transform` â€” never create a new one |
| LSTM out-of-memory on Kaggle | Batch size too large for GPU RAM | Use `batch_size=16` â€” monthly data has few samples, large batches waste memory |
| Local LSTM trains but metrics are poor | Architecture too shallow for patterns | Switch to the Kaggle Bidirectional model for production; local model is only for debugging |
| `early_stopping_rounds` param error in XGBoost | Moved to `.fit()` in XGBoost â‰¥ 2.0 | Pass it inside `.fit()` not in the constructor: `model.fit(X, y, early_stopping_rounds=10, ...)` |
| Excel sheet loads with wrong column names | Header rows skipped incorrectly | Use `skiprows=2` for CMPI/World Bank sheets; 0 for `SA Supplier Price Data` |

---

**Last Updated:** March 9, 2026  
**Status:** ðŸŸ¢ Active | **Next Milestone:** D1 â€” March 25, 2026
